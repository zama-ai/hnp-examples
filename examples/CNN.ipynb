{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN inference on encrypted MNIST\n",
    "\n",
    "In this example we train a CNN on plain data using Pytorch, then use the weights of this model to do the same inference with a numpy function, which can be later compiled to its homomorphic equivalent, to do inference on encrypted inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(73)\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    \"data\", train=True, download=True, transform=transforms.ToTensor()\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    \"data\", train=False, download=True, transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, hiddens=[256, 64, 32], output=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = torch.nn.Conv2d(\n",
    "            in_channels=1, out_channels=4, kernel_size=7, stride=3\n",
    "        )\n",
    "        self.fc1 = torch.nn.Linear(hiddens[0], hiddens[1])\n",
    "        self.fc2 = torch.nn.Linear(hiddens[1], hiddens[2])\n",
    "        self.fc3 = torch.nn.Linear(hiddens[2], output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = torch.sigmoid(self.conv(x))\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, n_epochs=10):\n",
    "    # model in training mode\n",
    "    model.train()\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        train_loss = 0.0\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # calculate average losses\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        print(\"Epoch: {} \\tTraining Loss: {:.6f}\".format(epoch, train_loss))\n",
    "\n",
    "    # model in evaluation mode\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=6e-4)\n",
    "model = train(model, train_loader, criterion, optimizer, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion):\n",
    "    # initialize lists to monitor test loss and accuracy\n",
    "    test_loss = 0.0\n",
    "    class_correct = list(0.0 for i in range(10))\n",
    "    class_total = list(0.0 for i in range(10))\n",
    "\n",
    "    # model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item()\n",
    "        # convert output probabilities to predicted class\n",
    "        _, pred = torch.max(output, 1)\n",
    "        # compare predictions to true label\n",
    "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "        # calculate test accuracy for each object class\n",
    "        for i in range(len(target)):\n",
    "            label = target.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "    # calculate and print avg test loss\n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    print(f\"Test Loss: {test_loss:.6f}\\n\")\n",
    "\n",
    "    for label in range(10):\n",
    "        print(\n",
    "            f\"Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% \"\n",
    "            f\"({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})\"\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        f\"\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% \"\n",
    "        f\"({int(np.sum(class_correct))}/{int(np.sum(class_total))})\"\n",
    "    )\n",
    "\n",
    "\n",
    "test(model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encrypted inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import hnumpy as hnp\n",
    "# conv2d is not a native numpy operation, so we provide it in npx\n",
    "import hnumpy.extended as npx\n",
    "import time\n",
    "\n",
    "DATA_RANGE = (0, 1.0)\n",
    "INPUT_SIZE = (28, 28)\n",
    "\n",
    "# extract weights\n",
    "kernels = model.conv.weight.detach().numpy()\n",
    "biases = model.conv.bias.detach().numpy()\n",
    "\n",
    "fc = {\n",
    "    1: (model.fc1.weight.T.detach().numpy(), model.fc1.bias.detach().numpy()),\n",
    "    2: (model.fc2.weight.T.detach().numpy(), model.fc2.bias.detach().numpy()),\n",
    "    3: (model.fc3.weight.T.detach().numpy(), model.fc3.bias.detach().numpy()),\n",
    "}\n",
    "\n",
    "\n",
    "# we implement the forward function of the Pytorch model as a numpy function so that we can compile it\n",
    "def inference(x):\n",
    "    # perform convolution\n",
    "    x = npx.conv2d(x, kernels, biases, stride=3).flatten()\n",
    "    x = 1 / (1 + np.exp(-x))\n",
    "    # forward through the linear layers + activation\n",
    "    for i in range(1, 4):\n",
    "        x = np.dot(x, fc[i][0]) + fc[i][1]\n",
    "        x = 1 / (1 + np.exp(-x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the function\n",
    "config = hnp.config.CompilationConfig(parameter_optimizer=\"handselected\")\n",
    "h = hnp.compile_fhe(\n",
    "    inference,\n",
    "    {\n",
    "        \"x\": hnp.encrypted_ndarray(bounds=DATA_RANGE, shape=INPUT_SIZE),\n",
    "    },\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate context and keys\n",
    "ctx = h.create_context()\n",
    "keys = ctx.keygen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first run the inference on the entire testset using the simulation mode, to make sure everything is working correctly, then we will run the encrypted inference on a subset of the testset and compare results against the plain evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the plain/simulated-encrypted inference and store outputs/timing\n",
    "\n",
    "# don't batch as we want one input at a time\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
    "\n",
    "expected_results = []\n",
    "results = []\n",
    "targets = []\n",
    "times = []\n",
    "\n",
    "n_iter = len(test_loader)\n",
    "for i, (data, target) in enumerate(test_loader):\n",
    "    print(f\"evaluation {i + 1}/{n_iter}\\r\", end=\"\")\n",
    "    x = data.detach().numpy().reshape(28, 28)\n",
    "    expected_results.append(inference(x))\n",
    "    tick = time.perf_counter()\n",
    "    # simulate encrypted inference\n",
    "    results.append(h.simulate(x))\n",
    "    tock = time.perf_counter()\n",
    "    times.append(tock - tick)\n",
    "    targets.append(target)\n",
    "\n",
    "# print results\n",
    "\n",
    "diff_plain_enc = 0\n",
    "diff_plain = 0\n",
    "diff_enc = 0\n",
    "for i in range(n_iter):\n",
    "    p = results[i].argmax()\n",
    "    ep = expected_results[i].argmax()\n",
    "    t = targets[i]\n",
    "    if p != ep:\n",
    "        diff_plain_enc += 1\n",
    "    if ep != t:\n",
    "        diff_plain += 1\n",
    "    if p != t:\n",
    "        diff_enc += 1\n",
    "\n",
    "print(f\"diff between encrypted (simulated) and plain output is {diff_plain_enc} out of {n_iter} computation\")\n",
    "print(f\"plain accuracy {(n_iter - diff_plain) / n_iter}\")\n",
    "print(f\"simulated enc accuracy {(n_iter - diff_enc) / n_iter}\")\n",
    "# first time include compilation\n",
    "print(f\"average time {sum(times) / n_iter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the plain/encrypted inference and store outputs/timing\n",
    "\n",
    "# don't batch as we want one input at a time\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
    "\n",
    "expected_results = []\n",
    "results = []\n",
    "targets = []\n",
    "times = []\n",
    "# run 10 examples only\n",
    "n_iter = 10\n",
    "for i, (data, target) in enumerate(test_loader):\n",
    "    print(f\"evaluation {i + 1}/{n_iter}\\r\", end=\"\")\n",
    "    x = data.detach().numpy().reshape(28, 28)\n",
    "    expected_results.append(inference(x))\n",
    "    tick = time.perf_counter()\n",
    "    # encrypted inference: comment the simulation and uncomment the encrypted inference\n",
    "    results.append(h.simulate(x))\n",
    "    # results.append(h.encrypt_and_run(keys, x))\n",
    "    tock = time.perf_counter()\n",
    "    times.append(tock - tick)\n",
    "    targets.append(target)\n",
    "    # you can remove the lines below if you want to test on the whole dataset\n",
    "    if i == n_iter - 1:\n",
    "        break\n",
    "        \n",
    "# print results\n",
    "\n",
    "diff_plain_enc = 0\n",
    "diff_plain = 0\n",
    "diff_enc = 0\n",
    "for i in range(n_iter):\n",
    "    p = results[i].argmax()\n",
    "    ep = expected_results[i].argmax()\n",
    "    t = targets[i]\n",
    "    if p != ep:\n",
    "        diff_plain_enc += 1\n",
    "    if ep != t:\n",
    "        diff_plain += 1\n",
    "    if p != t:\n",
    "        diff_enc += 1\n",
    "\n",
    "print(f\"diff between encrypted and plain output is {diff_plain_enc} out of {n_iter} computation\")\n",
    "print(f\"plain accuracy {(n_iter - diff_plain) / n_iter}\")\n",
    "print(f\"enc accuracy {(n_iter - diff_enc) / n_iter}\")\n",
    "# first time include compilation\n",
    "print(f\"average time {sum(times) / n_iter}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}