{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9096b681-62ea-4302-b604-2bac668f9646",
   "metadata": {},
   "source": [
    "## Problem: Sentiment Analysis\n",
    "\n",
    "`Needless to say, I wasted my money.` is a **negative** sentence.\n",
    "\n",
    "`Good case, Excellent value.` is a **positive** sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb32e5c-74e9-4c94-9163-9c3c6aa6b9bb",
   "metadata": {},
   "source": [
    "**Word Embeddings** are a way to represent words in a numerical way. They are generated by training on billions of sentences, based on the context in which words appear. Here is a visualization of word embeddings after applying Principal Component Analysis on them.\n",
    "![Word Embeddings](https://miro.medium.com/max/1280/1*mWerYTuy9xH4SlRY9fFg1A.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac65f58-8beb-4e22-9a07-dea99c1a0fd1",
   "metadata": {},
   "source": [
    "## Before starting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccf80823-0004-468a-86b8-2ba077d9b5ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hnumpy as hnp\n",
    "import io\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pickle\n",
    "import re\n",
    "import timeit\n",
    "import torch\n",
    "import urllib\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RAW_EMBEDDINGS_PATH = pathlib.Path(\"data/lstm/wiki-news-300d-1M.vec\")\n",
    "EMBEDDINGS_PATH = pathlib.Path(\"data/lstm/embeddings.pickle\")\n",
    "\n",
    "if not EMBEDDINGS_PATH.exists():\n",
    "    def load_word_embeddings(file):\n",
    "        fin = io.open(file, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "        n, d = map(int, fin.readline().split())\n",
    "        embeddings = {\n",
    "            \"indices\": {},\n",
    "            \"data\": np.zeros((n, d)),\n",
    "        }\n",
    "        for i, line in enumerate(fin):\n",
    "            tokens = line.rstrip().split(' ')\n",
    "            embeddings[\"indices\"][tokens[0]] = i\n",
    "            for j, value in enumerate(map(float, tokens[1:])):\n",
    "                embeddings[\"data\"][i, j] = value\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    if not RAW_EMBEDDINGS_PATH.exists():\n",
    "        url = \"https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\"\n",
    "        extract_dir = pathlib.Path(\"data\", \"lstm\")\n",
    "\n",
    "        zip_path, _ = urllib.request.urlretrieve(url)\n",
    "        with zipfile.ZipFile(zip_path, \"r\") as zip_file:\n",
    "            zip_file.extractall(extract_dir)\n",
    "\n",
    "    with open(EMBEDDINGS_PATH, \"wb\") as file:\n",
    "        pickle.dump(load_word_embeddings(RAW_EMBEDDINGS_PATH), file)\n",
    "else:\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18e893e-52c5-48f8-911c-458a2e4a69fd",
   "metadata": {},
   "source": [
    "## Here we go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05060fa7-e43e-4664-81be-b9cc980d7cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/lstm/embeddings.pickle\", \"rb\") as file:\n",
    "    embeddings = pickle.load(file)\n",
    "    embed = lambda tokens: embeddings[\"data\"][[embeddings[\"indices\"][token] for token in tokens], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c453139-242d-4296-b755-c8bf807b395b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11196\n"
     ]
    }
   ],
   "source": [
    "index = embeddings[\"indices\"][\"encryption\"]\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b139b18-ad27-4462-8c97-1455aa98572b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.000e-03 -1.992e-01 -4.550e-02  1.454e-01 -1.571e-01 -2.310e-02\n",
      "  1.353e-01 -1.410e-01 -4.920e-02  1.590e-02  1.834e-01 -1.863e-01\n",
      "  5.220e-02  4.200e-02 -6.340e-02  1.412e-01 -3.682e-01 -9.100e-02\n",
      " -2.147e-01  1.527e-01 -5.660e-01  4.370e-02 -1.274e-01  2.398e-01\n",
      "  1.387e-01 -8.950e-02  1.634e-01 -1.001e-01  1.094e-01  4.300e-02\n",
      " -1.049e-01  1.742e-01 -1.222e-01 -2.710e-02 -1.227e-01  5.100e-02\n",
      " -9.210e-02  4.490e-02  6.960e-02  3.200e-02  4.250e-02 -2.030e-02\n",
      "  1.830e-01  2.036e-01 -8.450e-02  6.350e-02 -6.380e-02  9.720e-02\n",
      "  1.447e-01 -6.450e-02 -7.830e-02 -8.050e-02 -8.305e-01  1.572e-01\n",
      "  3.028e-01 -3.560e-02  3.350e-01 -1.540e-01 -1.980e-02  1.585e-01\n",
      "  1.698e-01 -1.545e-01  3.230e-02 -2.000e-03 -2.580e-01 -5.160e-02\n",
      "  2.900e-02  8.570e-02  1.540e-02 -1.833e-01 -1.032e-01  1.003e-01\n",
      "  6.960e-02  8.000e-04 -7.060e-02 -1.465e-01  1.549e-01 -1.060e-01\n",
      "  1.040e-02  1.298e-01  1.740e-02 -1.158e-01 -1.030e-01 -1.747e-01\n",
      " -1.668e-01 -1.496e-01 -6.450e-02  2.748e-01  2.840e-01 -1.840e-01\n",
      " -5.100e-03 -2.194e-01 -2.440e-02 -5.340e-02  2.210e-02  1.037e-01\n",
      " -3.439e-01 -5.830e-02  1.709e-01 -2.740e-02 -1.395e-01 -2.033e-01\n",
      "  2.498e-01  9.100e-03 -2.720e-02 -1.573e-01 -1.546e-01  6.660e-02\n",
      " -7.500e-03  1.300e-01 -1.310e-02 -3.000e-02  1.650e-02 -1.686e-01\n",
      "  1.088e-01  5.640e-02  1.078e-01 -1.333e-01 -1.430e-01 -2.658e-01\n",
      "  2.405e-01  5.600e-02  6.300e-03  1.589e-01 -8.510e-02  1.685e-01\n",
      " -2.332e-01  4.790e-02  2.050e-02  6.180e-02  5.860e-02  1.556e-01\n",
      " -1.377e-01 -2.350e-02  4.220e-02  1.022e-01  1.663e-01  1.437e-01\n",
      " -1.180e-02  1.195e-01 -2.260e-02 -4.500e-03 -7.420e-02  5.570e-02\n",
      " -2.050e-02 -4.070e-02 -1.196e-01  5.500e-02 -4.800e-03  4.220e-02\n",
      "  1.000e-03  5.870e-02  1.634e-01  1.805e-01  1.600e-03  4.740e-02\n",
      " -1.991e-01  1.540e-02  4.370e-02  2.750e-02 -1.118e-01  2.210e-02\n",
      "  2.326e-01  1.332e-01  9.560e-02  1.490e-02  8.550e-02  4.000e-02\n",
      "  1.199e-01 -1.496e-01  4.890e-02 -6.840e-02 -9.200e-03  5.920e-02\n",
      " -3.540e-02 -9.180e-02  2.917e-01 -2.473e-01  2.720e-01 -1.320e-02\n",
      " -1.210e-02  3.250e-02  7.240e-02 -8.420e-02 -8.700e-02 -4.560e-02\n",
      " -5.400e-03 -1.391e-01 -3.270e-01 -6.790e-02 -1.556e-01  1.231e-01\n",
      " -1.687e-01 -1.670e-01 -2.046e-01 -2.863e-01 -8.480e-02  2.076e-01\n",
      "  1.447e-01  5.830e-02  6.620e-02  5.100e-02 -1.533e-01 -1.760e-01\n",
      "  1.182e-01 -1.178e-01  7.000e-04  1.724e-01  4.800e-03 -1.866e-01\n",
      " -4.570e-02  1.180e-01 -1.260e-01  1.274e-01 -5.030e-02 -1.186e-01\n",
      "  2.120e-02  1.171e-01 -1.070e-01 -6.510e-02  8.620e-02 -1.402e-01\n",
      "  1.820e-02  8.590e-02  9.640e-02 -3.413e-01 -2.410e-01 -9.130e-02\n",
      "  3.730e-02 -1.230e-01  9.580e-02 -4.100e-02  2.151e-01 -1.131e-01\n",
      " -2.400e-03 -7.830e-02 -2.764e-01 -1.567e-01 -1.798e-01  2.180e-02\n",
      "  6.140e-02 -1.444e-01 -1.564e-01  1.650e-01 -1.320e-01 -9.700e-02\n",
      " -1.939e-01 -1.147e-01  3.385e-01  4.218e-01 -9.350e-02 -1.003e-01\n",
      " -1.346e-01  6.890e-02 -1.030e-01 -1.403e-01  5.750e-02 -9.700e-03\n",
      " -8.440e-02  3.740e-02  7.500e-02  6.410e-02  5.270e-02  2.636e-01\n",
      " -4.003e-01 -5.600e-03  5.190e-02 -1.253e-01 -1.039e-01 -1.089e-01\n",
      " -1.320e-01 -1.428e-01 -1.230e-02 -3.480e-02 -1.166e-01  1.345e-01\n",
      " -1.384e-01  2.770e-01  2.362e-01 -2.601e-01 -9.780e-02  2.020e-02\n",
      "  3.340e-02  1.335e-01 -3.140e-02  1.038e-01  1.322e-01  1.197e-01\n",
      "  9.370e-02 -5.760e-02 -1.250e-02 -1.961e-01 -6.100e-03  5.210e-02\n",
      " -2.114e-01  1.377e-01  2.731e-01 -4.240e-02  2.360e-02 -5.880e-02]\n"
     ]
    }
   ],
   "source": [
    "embedding = embeddings[\"data\"][index, :]\n",
    "print(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de580abc-c28d-4ec7-a0d7-c002cd494030",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_ignore = []\n",
    "for word, index in embeddings[\"indices\"].items():\n",
    "    embedding = embeddings[\"data\"][index, :]\n",
    "    if embedding.min() < -1 or embedding.max() > 1:\n",
    "        words_to_ignore.append(word)\n",
    "for word in words_to_ignore:\n",
    "    del embeddings[\"indices\"][word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c681f2c3-1318-4049-86de-d59f04b70e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(sentence):\n",
    "    sentence = sentence.strip().lower()\n",
    "    sentence = re.sub(r\"[^\\w\\s]\", ' ', sentence)\n",
    "    sentence = re.sub(r\"\\s+\", ' ', sentence)\n",
    "    return embed(filter(lambda token: token != \"\", sentence.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1064f577-7868-4b25-9615-5509aea594d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 300)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"i like cookies\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f7e196c-03e7-4914-bc0d-4f4c19489fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATHS = [\"data/lstm/amazon.txt\", \"data/lstm/imdb.txt\", \"data/lstm/yelp.txt\"]\n",
    "\n",
    "DATASET = []\n",
    "for path in DATASET_PATHS:\n",
    "    with open(path, \"r\") as file:\n",
    "        for line in file:\n",
    "            [line, orientation] = line.strip().split('\\t')\n",
    "            try:\n",
    "                DATASET.append((encode(line), float(orientation)))\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc7a6923-d0da-497c-b324-00a66836230c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[-0.0154, -0.002 , -0.0725, ...,  0.1858,  0.105 , -0.0423],\n",
      "       [-0.0424,  0.007 , -0.1028, ...,  0.2318, -0.01  ,  0.0948],\n",
      "       [ 0.0156,  0.0752, -0.078 , ...,  0.0882, -0.0882, -0.0096],\n",
      "       ...,\n",
      "       [ 0.0242, -0.0265,  0.0822, ...,  0.0831, -0.0466,  0.0315],\n",
      "       [ 0.0047,  0.0223, -0.0087, ...,  0.1479,  0.1324, -0.0318],\n",
      "       [-0.0582, -0.1396, -0.045 , ...,  0.0076,  0.0079,  0.0541]]), 0.0)\n"
     ]
    }
   ],
   "source": [
    "print(DATASET[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a719030-a7cd-40dc-a912-60bcd967c092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2677\n"
     ]
    }
   ],
   "source": [
    "print(len(DATASET))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f296fe-96d7-4161-91bb-25dba7b0046f",
   "metadata": {},
   "source": [
    "![LSTM](https://miro.medium.com/max/666/1*vnqygSyLIA3QVTe6teca4Q.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "443a9a5e-7c45-4a0c-a067-0fcbefd2c799",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 100\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = torch.nn.LSTM(input_size=300, hidden_size=HIDDEN_SIZE)\n",
    "        self.fc = torch.nn.Linear(HIDDEN_SIZE, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (x, _) = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        return self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e053238-f55c-490e-9c9a-55a1314938ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 is completed...\n",
      "Epoch 2 is completed...\n",
      "Epoch 3 is completed...\n",
      "Epoch 4 is completed...\n",
      "Epoch 5 is completed...\n",
      "Epoch 6 is completed...\n",
      "Epoch 7 is completed...\n",
      "Epoch 8 is completed...\n",
      "Epoch 9 is completed...\n",
      "Epoch 10 is completed...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (lstm): LSTM(300, 100)\n",
       "  (fc): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 10\n",
    "\n",
    "model = Model()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "model.train()\n",
    "for i in range(EPOCHS):\n",
    "    for sentence, score in DATASET:\n",
    "        x = torch.tensor(sentence.reshape(-1, 1, 300))\n",
    "        prediction = model(x.float())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(prediction, torch.tensor([[[score]]]).float())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch\", i + 1, \"is completed...\", flush=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcfb12cc-bb35-4d5d-9a97-61723655bd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inferer:\n",
    "    def __init__(self, model):\n",
    "        parameters = list(model.lstm.parameters())\n",
    "\n",
    "        W_ii, W_if, W_ig, W_io = parameters[0].split(HIDDEN_SIZE)\n",
    "        W_hi, W_hf, W_hg, W_ho = parameters[1].split(HIDDEN_SIZE)\n",
    "        b_ii, b_if, b_ig, b_io = parameters[2].split(HIDDEN_SIZE)\n",
    "        b_hi, b_hf, b_hg, b_ho = parameters[3].split(HIDDEN_SIZE)\n",
    "\n",
    "        self.W_ii = W_ii.detach().numpy()\n",
    "        self.b_ii = b_ii.detach().numpy()\n",
    "\n",
    "        self.W_hi = W_hi.detach().numpy()\n",
    "        self.b_hi = b_hi.detach().numpy()\n",
    "\n",
    "        self.W_if = W_if.detach().numpy()\n",
    "        self.b_if = b_if.detach().numpy()\n",
    "\n",
    "        self.W_hf = W_hf.detach().numpy()\n",
    "        self.b_hf = b_hf.detach().numpy()\n",
    "\n",
    "        self.W_ig = W_ig.detach().numpy()\n",
    "        self.b_ig = b_ig.detach().numpy()\n",
    "\n",
    "        self.W_hg = W_hg.detach().numpy()\n",
    "        self.b_hg = b_hg.detach().numpy()\n",
    "\n",
    "        self.W_io = W_io.detach().numpy()\n",
    "        self.b_io = b_io.detach().numpy()\n",
    "\n",
    "        self.W_ho = W_ho.detach().numpy()\n",
    "        self.b_ho = b_ho.detach().numpy()\n",
    "\n",
    "        self.W = model.fc.weight.detach().numpy().T\n",
    "        self.b = model.fc.bias.detach().numpy()\n",
    "\n",
    "    def infer(self, x):\n",
    "        x_t, h_t, c_t = None, np.zeros(HIDDEN_SIZE), np.zeros(HIDDEN_SIZE)\n",
    "        for i in range(x.shape[0]):\n",
    "            x_t = x[i]\n",
    "            _, h_t, c_t = self.lstm_cell(x_t, h_t, c_t)\n",
    "\n",
    "        r = np.dot(h_t, self.W) + self.b\n",
    "        return self.sigmoid(r)\n",
    "\n",
    "    def lstm_cell(self, x_t, h_tm1, c_tm1):\n",
    "        i_t = self.sigmoid(\n",
    "            np.dot(self.W_ii, x_t) + self.b_ii + np.dot(self.W_hi, h_tm1) + self.b_hi\n",
    "        )\n",
    "        f_t = self.sigmoid(\n",
    "            np.dot(self.W_if, x_t) + self.b_if + np.dot(self.W_hf, h_tm1) + self.b_hf\n",
    "        )\n",
    "        g_t = np.tanh(\n",
    "            np.dot(self.W_ig, x_t) + self.b_ig + np.dot(self.W_hg, h_tm1) + self.b_hg\n",
    "        )\n",
    "        o_t = self.sigmoid(\n",
    "            np.dot(self.W_io, x_t) + self.b_io + np.dot(self.W_ho, h_tm1) + self.b_ho\n",
    "        )\n",
    "\n",
    "        c_t = f_t * c_tm1 + i_t * g_t\n",
    "        h_t = o_t * np.tanh(c_t)\n",
    "\n",
    "        return o_t, h_t, c_t\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a87c4ed-c83d-4422-a34d-f16625fda90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-04 13:18:00.548 | INFO     | hnumpy.convert:compile_fhe:376 - Compiling infer into an FHE function\n",
      "2021-06-04 13:18:00.549 | INFO     | hnumpy.convert:compile_fhe:378 - Checking input and output\n",
      "2021-06-04 13:18:00.644 | INFO     | hnumpy.convert:compile_homomorphic:262 - Create target graph\n",
      "2021-06-04 13:18:00.657 | INFO     | hnumpy.convert:compile_homomorphic:267 - Optimize target graph with optimizer `handselected`\n",
      "2021-06-04 13:18:01.855 | INFO     | hnumpy.convert:compile_homomorphic:282 - Correct encoding\n",
      "2021-06-04 13:18:01.866 | INFO     | hnumpy.convert:compile_homomorphic:285 - Create VM graph\n",
      "2021-06-04 13:18:01.886 | INFO     | hnumpy.convert:compile_homomorphic:301 - Return the result to the caller\n",
      "2021-06-04 13:18:01.894 | INFO     | hnumpy.client:keygen:28 - Creating 1 keyswitching key(s) and 1 bootstrapping key(s). This should take approximately 40 seconds (0.6666666666666666 minutes)\n",
      "2021-06-04 13:18:21.958 | DEBUG    | hnumpy.client:keygen:42 - Key creation time took 20.063458559990977 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target graph has 460 nodes and 91 of them are PBS...\n"
     ]
    }
   ],
   "source": [
    "SENTENCE_LENGTH_LIMIT = 5\n",
    "\n",
    "inferer = Inferer(model)\n",
    "homomorphic_inferer = hnp.compile_fhe(\n",
    "    inferer.infer,\n",
    "    {\n",
    "        \"x\": hnp.encrypted_ndarray(bounds=(-1, 1), shape=(SENTENCE_LENGTH_LIMIT, 300))\n",
    "    },\n",
    "    config=hnp.config.CompilationConfig(\n",
    "        parameter_optimizer=\"handselected\",\n",
    "        apply_topological_optimizations=True,\n",
    "        probabilistic_bounds=6,\n",
    "    ),\n",
    ")\n",
    "\n",
    "context = homomorphic_inferer.create_context()\n",
    "keys = context.keygen()\n",
    "\n",
    "operations = homomorphic_inferer.operation_count()\n",
    "pbses = homomorphic_inferer.pbs_count()\n",
    "\n",
    "print(\"\\nTarget graph has\", operations, \"nodes and\", pbses, \"of them are PBS...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a53ecc0-012a-4291-a3b2-71f61f4f0f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    try:\n",
    "        embedded = encode(sentence)\n",
    "    except KeyError as error:\n",
    "        print(\"! the word\", error, \"is unknown\")\n",
    "        return\n",
    "\n",
    "    if embedded.shape[0] > SENTENCE_LENGTH_LIMIT:\n",
    "        print(f\"! the sentence should not contain more than {SENTENCE_LENGTH_LIMIT} tokens\")\n",
    "        return\n",
    "\n",
    "    padded = np.zeros((SENTENCE_LENGTH_LIMIT, 300))\n",
    "    padded[SENTENCE_LENGTH_LIMIT - embedded.shape[0]:, :] = embedded\n",
    "\n",
    "    original = model(torch.tensor(padded.reshape((-1, 1, 300))).float()).detach().numpy()[0, 0, 0]\n",
    "    simulated = homomorphic_inferer.simulate(padded)[0]\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    actual = homomorphic_inferer.simulate(padded)[0]\n",
    "    # to run actual homomorphic computation, comment the line above and uncomment the one below",
    "    # actual = homomorphic_inferer.encrypt_and_run(keys, padded)[0]\n",
    "    end = timeit.default_timer()\n",
    "\n",
    "    if actual < 0.35:\n",
    "        print(\"- the sentence was negative\", end=' ')\n",
    "    elif actual > 0.65:\n",
    "        print(\"+ the sentence was positive\", end=' ')\n",
    "    else:\n",
    "        print(\"~ the sentence was neutral\", end=' ')\n",
    "\n",
    "    print(\n",
    "        f\"(\"\n",
    "        f\"original: {original * 100:.2f}%, \"\n",
    "        f\"simulated: {simulated * 100:.2f}%, \"\n",
    "        f\"actual: {actual * 100:.2f}%, \"\n",
    "        f\"difference: {np.abs(original - actual) * 100:.2f}%, \"\n",
    "        f\"took: {end - start:.3f} seconds\"\n",
    "        f\")\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "476be85c-980e-4ec9-a6b0-6c4c37a41766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- the sentence was negative (original: 0.01%, simulated: 0.01%, actual: 0.01%, difference: 0.01%, took: 31.229 seconds)\n"
     ]
    }
   ],
   "source": [
    "evaluate(\"Shipment was slow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6f796f9-4d6b-41da-94c0-0ffc4a9d0423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- the sentence was negative (original: 0.00%, simulated: 0.00%, actual: 0.01%, difference: 0.00%, took: 31.815 seconds)\n"
     ]
    }
   ],
   "source": [
    "evaluate(\"This product is a disgrace!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "865c3bcb-0ce4-43dc-82a5-1a6f39521d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ the sentence was positive (original: 99.47%, simulated: 99.19%, actual: 99.13%, difference: 0.34%, took: 31.160 seconds)\n"
     ]
    }
   ],
   "source": [
    "evaluate(\"It become my new favourite!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5253cbd6-d785-4fca-afbb-cb29cd53fa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ the sentence was positive (original: 99.94%, simulated: 99.93%, actual: 99.53%, difference: 0.41%, took: 31.254 seconds)\n"
     ]
    }
   ],
   "source": [
    "evaluate(\"This is perfect!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfcc005a-4c62-4475-a6a9-55de339902af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- the sentence was negative (original: 0.56%, simulated: 2.72%, actual: 2.55%, difference: 1.99%, took: 31.205 seconds)\n"
     ]
    }
   ],
   "source": [
    "evaluate(\"THIS IS A SCAM.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f38e5bd-1278-4ed1-90c6-4bf980f974eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- the sentence was negative (original: 0.08%, simulated: 0.22%, actual: 0.47%, difference: 0.40%, took: 31.208 seconds)\n"
     ]
    }
   ],
   "source": [
    "evaluate(\"Boring.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9770ed19-ccf3-487c-b899-4fbcef846cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ the sentence was positive (original: 99.98%, simulated: 99.98%, actual: 99.85%, difference: 0.12%, took: 31.268 seconds)\n"
     ]
    }
   ],
   "source": [
    "evaluate(\"Fun!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ec4e0ae-e340-4501-9a63-b13c530d079f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- the sentence was negative (original: 0.02%, simulated: 0.11%, actual: 0.54%, difference: 0.52%, took: 31.240 seconds)\n"
     ]
    }
   ],
   "source": [
    "evaluate(\"I would rather burn money.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d9b39c3e-adce-448f-9354-48808e72c980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ the sentence was positive (original: 99.80%, simulated: 99.59%, actual: 99.98%, difference: 0.18%, took: 31.208 seconds)\n"
     ]
    }
   ],
   "source": [
    "evaluate(\"Great view.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f0fa1b7-6413-4599-9b6b-7fddc76eb077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ the sentence was positive (original: 99.82%, simulated: 99.79%, actual: 99.80%, difference: 0.02%, took: 31.801 seconds)\n"
     ]
    }
   ],
   "source": [
    "evaluate(\"I am happy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6afda331-36d5-48b9-ae57-306bc555c548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ the sentence was positive (original: 99.94%, simulated: 99.91%, actual: 98.78%, difference: 1.16%, took: 31.210 seconds)\n"
     ]
    }
   ],
   "source": [
    "evaluate(\"What a lovely place!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41297eee-ac27-4966-94d3-0518a62cd4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- the sentence was negative (original: 0.00%, simulated: 0.00%, actual: 0.00%, difference: 0.00%, took: 31.294 seconds)\n"
     ]
    }
   ],
   "source": [
    "evaluate(\"It is bad, really bad!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d42596e6-b1ef-4869-9d76-ed7d8ea254ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ the sentence was positive (original: 87.32%, simulated: 88.21%, actual: 76.75%, difference: 10.57%, took: 31.243 seconds)\n"
     ]
    }
   ],
   "source": [
    "evaluate(\"It is like a dream!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6651e84f-0b21-4a6b-aeb0-aed2979406f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- the sentence was negative (original: 0.00%, simulated: 0.01%, actual: 0.05%, difference: 0.05%, took: 31.302 seconds)\n"
     ]
    }
   ],
   "source": [
    "evaluate(\"It was like a nightmare!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4586013-469f-46b0-923c-f62128a4a4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
